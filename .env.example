# ============================================================================
# MediScope Configuration - LM Studio + Vision Model Setup
# ============================================================================

# Application Settings
# ----------------------------------------------------------------------------
APP_NAME=MediScope
APP_VERSION=0.2.0
ENVIRONMENT=local  # local, development, staging, production
LOG_LEVEL=INFO     # DEBUG, INFO, WARNING, ERROR, CRITICAL
ALLOWED_ORIGINS=http://localhost:8000,http://127.0.0.1:8000

# Feature Flags
# ----------------------------------------------------------------------------
DEMO_MODE=false
ENABLE_FILE_LOGGING=true

# Upload Limits
# ----------------------------------------------------------------------------
MAX_UPLOAD_MB=20

# Service Providers
# ----------------------------------------------------------------------------
# RAG: simple, llamaindex
RAG_PROVIDER=llamaindex

# LLM: none, openai, vllm, lmstudio
# Using LM Studio for local medical text generation
LLM_PROVIDER=lmstudio
LLM_MODEL=towardsinnovationlab/qwen3-medical-gguf

# STT: none, faster_whisper, openai
STT_PROVIDER=faster_whisper

# TTS: none, gtts, coqui
TTS_PROVIDER=gtts

# Vision: none, internvl
# Using InternVL for medical image analysis
# Default: http://localhost:1234 (LM Studio default port)
VISION_PROVIDER=lmstudio
VISION_MODEL=Qwen/Qwen3-VL-2B-Instruct
LMSTUDIO_URL=http://localhost:1234

# OCR: none, tesseract
OCR_PROVIDER=none

# API Keys and URLs
# ----------------------------------------------------------------------------
# OpenAI API key (required if using openai provider)
OPENAI_API_KEY=

# vLLM server URL (required if using vllm provider)
VLLM_URL=http://vllm:8000

# LM Studio local server URL (required if using lmstudio provider)

# Timeouts (in seconds)
# ----------------------------------------------------------------------------
LLM_TIMEOUT=300
STT_TIMEOUT=200
TTS_TIMEOUT=200
VISION_TIMEOUT=200
HTTP_TIMEOUT=120

# Retry Settings
# ----------------------------------------------------------------------------
MAX_RETRIES=3
RETRY_DELAY=1.0

# ============================================================================
# Setup Instructions
# ============================================================================
# 
# 1. Install LM Studio from: https://lmstudio.ai/
# 2. Download model: towardsinnovationlab/qwen3-medical-gguf (Q4_K_M recommended)
# 3. Load model in LM Studio
# 4. Start server on port 1234
# 5. Run: pip install -r backend/requirements-ml.txt
# 6. Start MediScope: run.bat
#
# For detailed guide, see: LMSTUDIO_SETUP.md (English) or SETUP_BANGLA.md (বাংলা)
# ============================================================================
